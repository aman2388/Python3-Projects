{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the skills I learned from 365 Data Science Bootcamp, I have created a machine learning model that recognizes fraudulent credit card transactions. Dataset downloaded from https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "The .csv summarises the data. Columns V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Column 'Time' contains the seconds taken between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Column 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "This is a classification problem with two classes. The main idea is to detect more accurately of both fraud and non-fraud transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('creditcard_fraud_train.npz')\n",
    "\n",
    "# extract the inputs using the keyword under which we saved them\n",
    "# cast the inputs to float\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "# cast the targets to sparse_categorical_crossentropy so we can smoothly one-hot encode them\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# load the validation data in the temporary variable\n",
    "npz = np.load('creditcard_fraud_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('creditcard_fraud_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Outline, optimizers, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 0.8062 - accuracy: 0.4828 - val_loss: 0.5994 - val_accuracy: 0.7041\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.5231 - accuracy: 0.8158 - val_loss: 0.4168 - val_accuracy: 0.9184\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.3740 - accuracy: 0.8983 - val_loss: 0.3055 - val_accuracy: 0.9388\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2814 - accuracy: 0.9301 - val_loss: 0.2315 - val_accuracy: 0.9592\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2191 - accuracy: 0.9390 - val_loss: 0.1812 - val_accuracy: 0.9592\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.1772 - accuracy: 0.9454 - val_loss: 0.1448 - val_accuracy: 0.9592\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.1458 - accuracy: 0.9581 - val_loss: 0.1191 - val_accuracy: 0.9592\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.1235 - accuracy: 0.9606 - val_loss: 0.0995 - val_accuracy: 0.9796\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.1060 - accuracy: 0.9644 - val_loss: 0.0845 - val_accuracy: 0.9796\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.0929 - accuracy: 0.9670 - val_loss: 0.0734 - val_accuracy: 0.9694\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.0644 - val_accuracy: 0.9694\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.0724 - accuracy: 0.9746 - val_loss: 0.0565 - val_accuracy: 0.9796\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.0647 - accuracy: 0.9759 - val_loss: 0.0514 - val_accuracy: 0.9898\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.0582 - accuracy: 0.9784 - val_loss: 0.0468 - val_accuracy: 0.9898\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.0524 - accuracy: 0.9809 - val_loss: 0.0420 - val_accuracy: 0.9898\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.0407 - val_accuracy: 0.9898\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.0426 - accuracy: 0.9886 - val_loss: 0.0379 - val_accuracy: 0.9898\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.0382 - accuracy: 0.9886 - val_loss: 0.0345 - val_accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0303 - val_accuracy: 0.9898\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0327 - val_accuracy: 0.9898\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.0284 - accuracy: 0.9949 - val_loss: 0.0289 - val_accuracy: 0.9898\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.0256 - accuracy: 0.9962 - val_loss: 0.0281 - val_accuracy: 0.9898\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.0231 - accuracy: 0.9962 - val_loss: 0.0250 - val_accuracy: 0.9898\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.0254 - val_accuracy: 0.9898\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.0260 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be1f983100>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the input and output sizes\n",
    "input_size = 30\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "# define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# set an early stopping mechanism\n",
    "# set patience=2, to be a bit tolerant against random validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# fit the model\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs,\n",
    "          #check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "Test the final prediction power of the model by running it on the test dataset that the algorithm has never seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 748us/step - loss: 0.0371 - accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.04. Test accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
